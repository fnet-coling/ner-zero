{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "from random import randint\n",
    "from data_load import *\n",
    "def getLabelLinks(fn):\n",
    "    return processLines(fn,lambda x,y:addFeature(x,y.rstrip().split('\\t')),list())\n",
    "in_dir= \"/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN\"\n",
    "a=MentionData('/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN/train_x_new.txt',\n",
    "              \"/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN/train_y.txt\",\n",
    "             in_dir+\"/feature.txt\",in_dir+\"/type.txt\")\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "\n",
    "cimport numpy as np\n",
    "from random import randint\n",
    "import sys\n",
    "import cython\n",
    "\n",
    "import math\n",
    "from libc.stdlib cimport malloc, free\n",
    "\n",
    "from libc.math cimport exp\n",
    "from libc.math cimport log\n",
    "from libc.math cimport sqrt\n",
    "from libc.string cimport memset\n",
    "import random\n",
    "# scipy <= 0.15\n",
    "\n",
    "import scipy.linalg.blas as fblas\n",
    "ctypedef np.float32_t REAL_t\n",
    "cdef int ONE = 1\n",
    "\n",
    "\n",
    "REAL = np.float32\n",
    "cdef extern from \"/Users/mayk/working/figer/baseline/PLE/Model/warp/voidptr.h\":\n",
    "    void* PyCObject_AsVoidPtr(object obj)\n",
    "DEF MAX_SENTENCE_LEN = 10000\n",
    "ctypedef void (*scopy_ptr) (const int *N, const float *X, const int *incX, float *Y, const int *incY) nogil\n",
    "ctypedef void (*saxpy_ptr) (const int *N, const float *alpha, const float *X, const int *incX, float *Y, const int *incY) nogil\n",
    "ctypedef float (*sdot_ptr) (const int *N, const float *X, const int *incX, const float *Y, const int *incY) nogil\n",
    "ctypedef double (*dsdot_ptr) (const int *N, const float *X, const int *incX, const float *Y, const int *incY) nogil\n",
    "ctypedef double (*snrm2_ptr) (const int *N, const float *X, const int *incX) nogil\n",
    "ctypedef void (*sscal_ptr) (const int *N, const float *alpha, const float *X, const int *incX) nogil\n",
    "\n",
    "\n",
    "cdef scopy_ptr scopy = <scopy_ptr>PyCObject_AsVoidPtr(fblas.scopy._cpointer)  # y = x\n",
    "cdef saxpy_ptr saxpy=<saxpy_ptr>PyCObject_AsVoidPtr(fblas.saxpy._cpointer)  # y += alpha * x\n",
    "cdef sdot_ptr sdot=<sdot_ptr>PyCObject_AsVoidPtr(fblas.sdot._cpointer)  # float = dot(x, y)\n",
    "cdef dsdot_ptr dsdot=<dsdot_ptr>PyCObject_AsVoidPtr(fblas.sdot._cpointer)  # double = dot(x, y)\n",
    "cdef snrm2_ptr snrm2=<snrm2_ptr>PyCObject_AsVoidPtr(fblas.snrm2._cpointer)  # sqrt(x^2)\n",
    "cdef sscal_ptr sscal=<sscal_ptr>PyCObject_AsVoidPtr(fblas.sscal._cpointer) # x = alpha * x\n",
    "DEF EXP_TABLE_SIZE = 10000\n",
    "DEF MAX_EXP = 50\n",
    "\n",
    "cdef REAL_t[EXP_TABLE_SIZE] EXP_TABLE\n",
    "cdef REAL_t[EXP_TABLE_SIZE] LOG_TABLE\n",
    "\n",
    "cdef REAL_t ONEF = <REAL_t>1.0\n",
    "\n",
    "# for when fblas.sdot returns a double\n",
    "cdef REAL_t our_dot_double(const int *N, const float *X, const int *incX, const float *Y, const int *incY) nogil:\n",
    "    return <REAL_t>dsdot(N, X, incX, Y, incY)\n",
    "\n",
    "# for when fblas.sdot returns a float\n",
    "cdef REAL_t our_dot_float(const int *N, const float *X, const int *incX, const float *Y, const int *incY) nogil:\n",
    "    return <REAL_t>sdot(N, X, incX, Y, incY)\n",
    "\n",
    "# for when no blas available\n",
    "cdef REAL_t our_dot_noblas(const int *N, const float *X, const int *incX, const float *Y, const int *incY) nogil:\n",
    "    # not a true full dot()-implementation: just enough for our cases\n",
    "    cdef int i\n",
    "    cdef REAL_t a\n",
    "    a = <REAL_t>0.0\n",
    "    for i from 0 <= i < 50 by 1:\n",
    "        a += X[i] * Y[i]\n",
    "    return a\n",
    "\n",
    "# for when no blas available\n",
    "cdef void our_saxpy_noblas(const int *N, const float *alpha, const float *X, const int *incX, float *Y, const int *incY) nogil:\n",
    "    cdef int i\n",
    "    for i from 0 <= i < N[0] by 1:\n",
    "        Y[i * (incY[0])] = (alpha[0]) * X[i * (incX[0])] + Y[i * (incY[0])]\n",
    "cdef REAL_t cvdot(vec1,vec2,size):\n",
    "    cdef int csize = size\n",
    "    f= dsdot(&csize,<REAL_t *>(np.PyArray_DATA(vec1)),&ONE,<REAL_t *>(np.PyArray_DATA(vec2)),&ONE)\n",
    "    return f\n",
    "def csaxpy(vec1,vec2,alpha,size):\n",
    "    cdef int csize = size\n",
    "    cdef float calpha = alpha\n",
    "    f= our_saxpy_noblas(&csize,&calpha,<REAL_t *>(np.PyArray_DATA(vec1)),&ONE,<REAL_t *>(np.PyArray_DATA(vec2)),&ONE)\n",
    "    return f\n",
    "cdef REAL_t crank(int k):\n",
    "    cdef REAL_t loss = 0.\n",
    "    cdef int i = 1\n",
    "    for i in xrange(1,k+1):\n",
    "        loss += ONEF/i\n",
    "    return loss\n",
    "cdef REAL_t vsum(REAL_t *vec,int *size):\n",
    "    cdef int i\n",
    "    cdef REAL_t product\n",
    "    product = <REAL_t>0.0\n",
    "    for i from 0 <= i < size[0] by 1:\n",
    "        product += vec[i] * vec[i]\n",
    "    return np.sqrt(product)\n",
    "def cnorm(vec):\n",
    "    cdef int size\n",
    "    size  = len(vec)\n",
    "    return vsum(<REAL_t *>(np.PyArray_DATA(vec)),&size)\n",
    "def init():\n",
    "    for i in range(EXP_TABLE_SIZE):\n",
    "        EXP_TABLE[i] = <REAL_t>exp((i / <REAL_t>EXP_TABLE_SIZE * 2 - 1) * MAX_EXP)\n",
    "        EXP_TABLE[i] = <REAL_t>(EXP_TABLE[i] / (EXP_TABLE[i] + 1))\n",
    "\n",
    "cdef void divide(REAL_t *vec, const float *alpha, const int *size):\n",
    "    cdef int i\n",
    "    cdef REAL_t product\n",
    "    for i from 0 <= i < size[0] by 1:\n",
    "        vec[i] = vec[i]/alpha[0]\n",
    "def cdivide(vec,alpha):\n",
    "    cdef int size\n",
    "    size  = len(vec)\n",
    "    cdef float r = alpha\n",
    "    divide(<REAL_t *>(np.PyArray_DATA(vec)),&r,&size)\n",
    "init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuples = getLabelLinks('/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN/type_type_kb.txt')\n",
    "tuples = [ (int(t[0]),int(t[1]),float(t[2]))for t in tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-7e7a87d0c424>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-7e7a87d0c424>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    cdef REAL_t error = 0\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def softmax_labelCorr_gradient(B,tup,weight,size,lr=0.01):\n",
    "    #print B\n",
    "    #print B[0]-B[9]\n",
    "\n",
    "    dA = np.zeros(size,dtype=REAL)\n",
    "    random.seed(1)\n",
    "    x = np.mean(A[inst.features],axis=0)\n",
    "    cdef REAL_t error = 0\n",
    "    cdef REAL_t s1,s2,logs1,logs2,g\n",
    "    cdef clr = lr\n",
    "    cdef int neg_num = len(inst.negative_labels)\n",
    "    cdef REAL_t norm\n",
    "    cdef REAL_t pos = ONEF\n",
    "    cdef int csize =size\n",
    "    for l in inst.sparse_labels:\n",
    "        logs1= cvdot(x,B[l],50)\n",
    "        if  logs1 <= -MAX_EXP or  logs1 >= MAX_EXP:\n",
    "            continue\n",
    "        s1 = EXP_TABLE[<int>((logs1 + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))]\n",
    "        error -=logs1\n",
    "        g = (pos - s1) * clr\n",
    "        csaxpy(B[l],dA,g,50)\n",
    "        saxpy(&csize, &g, <REAL_t *>(np.PyArray_DATA(x)), &ONE, <REAL_t *>(np.PyArray_DATA(B[l])), &ONE)\n",
    "        for k in xrange(neg_num):\n",
    "            nl = inst.negative_labels[randint(0,neg_num-1)]\n",
    "            logs2 = cvdot(x,B[nl],50)\n",
    "            if  logs2 <= -MAX_EXP or  logs2 >= MAX_EXP:\n",
    "                continue\n",
    "            s2 = EXP_TABLE[<int>((logs2 + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))]\n",
    "            if s2 > s1:\n",
    "                g =  (-s2) * clr\n",
    "                csaxpy(B[nl],dA,g,50)\n",
    "    \n",
    "                saxpy(&csize, &g, <REAL_t *>(np.PyArray_DATA(x)), &ONE, <REAL_t *>(np.PyArray_DATA(B[nl])), &ONE)\n",
    "\n",
    "                error += logs2\n",
    "    \n",
    "\n",
    "    for f in inst.features:\n",
    "        csaxpy(dA,A[f],clr,50)\n",
    "        norm = cnorm(A[f])\n",
    "        #if norm >1:\n",
    "         #   cdivide(A[f],norm)\n",
    "\n",
    "    for i in xrange(len(B)):\n",
    "        norm =  cnorm(B[i])\n",
    "       # if norm >1:\n",
    "        #    cdivide(B[i],norm)\n",
    "            #B[i] /=norm\n",
    "    return error\n",
    "\n",
    "def label_train(B,insts,gradient,max_it=10):\n",
    "    cdef float error\n",
    "    \n",
    "    for it in xrange(1,max_it+1):\n",
    "        error = 0.\n",
    "        for i,inst in enumerate(insts):\n",
    "            error+=gradient(B,inst,size,lr=lr)\n",
    "        \n",
    "            if i % (len(insts)/100+1) ==0:\n",
    "                sys.stdout.write(\"\\rIteration %d \" % (it)+ \"trained {0:.0f}%\".format(float(i)*100/len(insts))+\" Loss:{0:.2f}\".format(error))\n",
    "                sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corrReg(B,tup,weight,size):\n",
    "    diff = B[tup[0]] - B[tup[1]]\n",
    "    B[tup[0]] -= weight*diff\n",
    "    B[tup[1]] += weight*diff\n",
    "    norm = np.linalg.norm(diff)\n",
    "    return norm * norm * weight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8446403"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B= np.random.rand(len(a.label2id),50).astype(np.float32)\n",
    "corrReg(B,tuples[0],0.1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
