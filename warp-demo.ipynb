{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.matutils import argsort\n",
    "from numpy import array,asarray\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_embed = model.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fmodel_embed = fmodel.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class WARPModel:\n",
    "    def __init__(self,label_vec_f,feature_vec_f,binary=False):\n",
    "        label2vec = Word2Vec.load_word2vec_format(label_vec_f,binary=binary)\n",
    "        self.label_embed =  label2vec.syn0\n",
    "        self.dictionary = label2vec.index2word\n",
    "        \n",
    "        self.feat_embed = Word2Vec.load_word2vec_format(feature_vec_f,binary=binary).syn0\n",
    "    def scores(self,X):\n",
    "        return np.dot(np.sum(self.feat_embed[X],axis=0),self.label_embed.T)\n",
    "    def label_rank(self,X):\n",
    "        return map(lambda x:self.dictionary[x],argsort(self.scores(X),reverse=True))\n",
    "    def batch_predict(self,Xs):\n",
    "        return [self.label_rank(X)[:2] for X in Xs]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = WARPModel('/Users/mayk/working/figer/baseline/PLE/Results/warp_B.bin','/Users/mayk/working/figer/baseline/PLE/Results/warp_A.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fn):\n",
    "    data = []\n",
    "    with open(fn,'r') as f:\n",
    "        for ln in f:\n",
    "            data.append(map(int,ln.rstrip().split()[1].split(',')))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=read_data('/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN/test_x.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls = model.label_rank(data[4])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def refine(labels,maxDepth=2,delim='/'):\n",
    "    keep = [\"\"]*maxDepth\n",
    "    for l in labels:\n",
    "        path = getPath(l,delim)\n",
    "        for i in range(len(path)):\n",
    "            if keep[i] ==\"\" and path[i]!=\"\":\n",
    "                keep[i] = path[i]\n",
    "    results = []\n",
    "    tmp= ''\n",
    "    for l in keep:\n",
    "        if l!=\"\":\n",
    "            tmp+=delim\n",
    "            tmp +=l\n",
    "            results.append(tmp)\n",
    "        \n",
    "    return results        \n",
    "def getPath(label,delim='/'):\n",
    "    return label.split(delim)[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from DataIO import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data='../../Data/BBN/'\n",
    "outdir='../../Results/'\n",
    "data='../../Intermediate/BBN/'\n",
    "output = outdir+'/predictionInText_warp.txt'\n",
    "type_file = data + '/type.txt'\n",
    "mention_file = data + '/mention.txt'\n",
    "json_file = raw_data + '/test.json'\n",
    "test_y_file = outdir+ 'warp_predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mention_mapping = load_map(mention_file, 'mention')\n",
    "label_mapping = load_map(type_file, 'label')\n",
    "clean_mentions = load_mention_type(test_y_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def casestudy(filename, output, mention_mapping, label_mapping, clean_mentions):\n",
    "    with open(filename) as f, open(output, 'w') as g:\n",
    "        for line in f:\n",
    "            sent = json.loads(line.strip('\\r\\n'))\n",
    "            result = putback(sent, mention_mapping, label_mapping, clean_mentions)\n",
    "            if result is not '':\n",
    "                g.write(result+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "casestudy(json_file, output, mention_mapping, label_mapping, clean_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def putback(sent_json, mention_mapping, label_mapping, clean_mentions):\n",
    "    fileid = sent_json['fileid']\n",
    "    senid = sent_json['senid']\n",
    "    tokens = sent_json['tokens']\n",
    "    pivot = 0\n",
    "    result = []\n",
    "    mentions = sent_json['mentions']\n",
    "    sorted_m = sorted(mentions, cmp=compare)\n",
    "    for m in sorted_m:\n",
    "        start = m['start']\n",
    "        end = m['end']\n",
    "        if end - start == 1:\n",
    "            mention_name = '[%s]' % (tokens[start])\n",
    "        else:\n",
    "            mention_name = '[%s]' % (' '.join(tokens[start:end]))\n",
    "        if pivot <= start:\n",
    "            result.extend(tokens[pivot:start])\n",
    "            result.append(mention_name)\n",
    "            # find predicted labels if any\n",
    "            m_name = '%s_%d_%d_%d'%(fileid, senid, start, end)\n",
    "            if m_name in mention_mapping:\n",
    "                m_id = mention_mapping[m_name]\n",
    "                if m_id in clean_mentions:\n",
    "                    clean_labels = [label_mapping[l] for l in clean_mentions[m_id]]\n",
    "                    result.append(':'+'['+','.join(clean_labels)+']')\n",
    "        pivot = end\n",
    "    if pivot < len(tokens):\n",
    "        result.extend(tokens[pivot:])\n",
    "    result = ' '.join([x for x in result if x is not None])\n",
    "    return fileid+':'+str(senid)+'\\t'+result + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare(item1, item2):\n",
    "    if item1['start'] != item2['start']:\n",
    "        return item1['start'] - item2['start']\n",
    "    else:\n",
    "        return item2['end'] - item1['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "data = '/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN/'\n",
    "id2mention = defaultdict()\n",
    "mention2id= defaultdict()\n",
    "with open(data+'mention.txt','rb') as mf:\n",
    "    for ln in mf:\n",
    "        mid,iid = ln.rstrip().split()\n",
    "        mention2id[mid]=iid   \n",
    "        id2mention[iid]=mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(test_y_fn,idmap,out_fn):\n",
    "    out = open(out_fn,'wb')\n",
    "    with open(test_y_fn,'r') as Ys:\n",
    "        for ln in Ys:\n",
    "            mid,labels = ln.rstrip().split('\\t')\n",
    "            mid = idmap[mid]\n",
    "            for l in labels.split(','):\n",
    "                out.write('%s\\t%s\\t1\\n' % (mid,l))\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert('/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN/test_y.txt',mention2id,'/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN/test_y_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
