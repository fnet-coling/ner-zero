{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from mention import *\n",
    "from collections import Counter\n",
    "from math import log\n",
    "from gensim.matutils import argsort\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from random import randint\n",
    "from data_load import *\n",
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "\n",
    "cimport numpy as np\n",
    "from random import randint\n",
    "import sys\n",
    "import cython\n",
    "cdef extern from \"math.h\":\n",
    "    double sqrt(double m)\n",
    "import math\n",
    "from libc.stdlib cimport malloc, free\n",
    "\n",
    "from libc.math cimport exp\n",
    "from libc.math cimport log\n",
    "from gensim.matutils import argsort\n",
    "\n",
    "from libc.string cimport memset\n",
    "import random\n",
    "# scipy <= 0.15\n",
    "\n",
    "import scipy.linalg.blas as fblas\n",
    "ctypedef np.float32_t REAL_t\n",
    "cdef int ONE = 1\n",
    "\n",
    "\n",
    "REAL = np.float32\n",
    "cdef extern from \"/Users/mayk/working/figer/baseline/PLE/Model/warp/voidptr.h\":\n",
    "    void* PyCObject_AsVoidPtr(object obj)\n",
    "DEF MAX_SENTENCE_LEN = 10000\n",
    "ctypedef void (*scopy_ptr) (const int *N, const float *X, const int *incX, float *Y, const int *incY) nogil\n",
    "ctypedef void (*saxpy_ptr) (const int *N, const float *alpha, const float *X, const int *incX, float *Y, const int *incY) nogil\n",
    "ctypedef float (*sdot_ptr) (const int *N, const float *X, const int *incX, const float *Y, const int *incY) nogil\n",
    "ctypedef double (*dsdot_ptr) (const int *N, const float *X, const int *incX, const float *Y, const int *incY) nogil\n",
    "ctypedef double (*snrm2_ptr) (const int *N, const float *X, const int *incX) nogil\n",
    "ctypedef void (*sscal_ptr) (const int *N, const float *alpha, const float *X, const int *incX) nogil\n",
    "\n",
    "\n",
    "cdef scopy_ptr scopy = <scopy_ptr>PyCObject_AsVoidPtr(fblas.scopy._cpointer)  # y = x\n",
    "cdef saxpy_ptr saxpy=<saxpy_ptr>PyCObject_AsVoidPtr(fblas.saxpy._cpointer)  # y += alpha * x\n",
    "cdef sdot_ptr sdot=<sdot_ptr>PyCObject_AsVoidPtr(fblas.sdot._cpointer)  # float = dot(x, y)\n",
    "cdef dsdot_ptr dsdot=<dsdot_ptr>PyCObject_AsVoidPtr(fblas.sdot._cpointer)  # double = dot(x, y)\n",
    "cdef snrm2_ptr snrm2=<snrm2_ptr>PyCObject_AsVoidPtr(fblas.snrm2._cpointer)  # sqrt(x^2)\n",
    "cdef sscal_ptr sscal=<sscal_ptr>PyCObject_AsVoidPtr(fblas.sscal._cpointer) # x = alpha * x\n",
    "DEF EXP_TABLE_SIZE = 10000\n",
    "DEF MAX_EXP = 50\n",
    "\n",
    "cdef REAL_t[EXP_TABLE_SIZE] EXP_TABLE\n",
    "cdef REAL_t[EXP_TABLE_SIZE] LOG_TABLE\n",
    "\n",
    "cdef REAL_t ONEF = <REAL_t>1.0\n",
    "\n",
    "# for when fblas.sdot returns a double\n",
    "cdef REAL_t our_dot_double(const int *N, const float *X, const int *incX, const float *Y, const int *incY) nogil:\n",
    "    return <REAL_t>dsdot(N, X, incX, Y, incY)\n",
    "\n",
    "# for when fblas.sdot returns a float\n",
    "cdef REAL_t our_dot_float(const int *N, const float *X, const int *incX, const float *Y, const int *incY) nogil:\n",
    "    return <REAL_t>sdot(N, X, incX, Y, incY)\n",
    "\n",
    "# for when no blas available\n",
    "cdef REAL_t our_dot_noblas(const int *N, const float *X, const int *incX, const float *Y, const int *incY) nogil:\n",
    "    # not a true full dot()-implementation: just enough for our cases\n",
    "    cdef int i\n",
    "    cdef REAL_t a\n",
    "    a = <REAL_t>0.0\n",
    "    for i from 0 <= i < 50 by 1:\n",
    "        a += X[i] * Y[i]\n",
    "    return a\n",
    "\n",
    "# for when no blas available\n",
    "cdef void our_saxpy_noblas(const int *N, const float *alpha, const float *X, const int *incX, float *Y, const int *incY) nogil:\n",
    "    cdef int i\n",
    "    for i from 0 <= i < N[0] by 1:\n",
    "        Y[i * (incY[0])] = (alpha[0]) * X[i * (incX[0])] + Y[i * (incY[0])]\n",
    "cdef REAL_t cvdot(vec1,vec2,size):\n",
    "    cdef int csize = size\n",
    "    f= dsdot(&csize,<REAL_t *>(np.PyArray_DATA(vec1)),&ONE,<REAL_t *>(np.PyArray_DATA(vec2)),&ONE)\n",
    "    return f\n",
    "def csaxpy(vec1,vec2,alpha,size):\n",
    "    cdef int csize = size\n",
    "    cdef float calpha = alpha\n",
    "    f= our_saxpy_noblas(&csize,&calpha,<REAL_t *>(np.PyArray_DATA(vec1)),&ONE,<REAL_t *>(np.PyArray_DATA(vec2)),&ONE)\n",
    "    return f\n",
    "cdef REAL_t crank(int k):\n",
    "    cdef REAL_t loss = 0.\n",
    "    cdef int i = 1\n",
    "    for i in range(1,k+1):\n",
    "        loss += ONEF/i\n",
    "    return loss\n",
    "cdef REAL_t vsum(REAL_t *vec,int *size):\n",
    "    cdef int i\n",
    "    cdef REAL_t product\n",
    "    product = <REAL_t>0.0\n",
    "    for i from 0 <= i < size[0] by 1:\n",
    "        product += vec[i] **2\n",
    "    return sqrt(product)\n",
    "def cnorm(vec):\n",
    "    cdef int size\n",
    "    size  = len(vec)\n",
    "    return vsum(<REAL_t *>(np.PyArray_DATA(vec)),&size)\n",
    "def init():\n",
    "    for i in range(EXP_TABLE_SIZE):\n",
    "        EXP_TABLE[i] = <REAL_t>exp((i / <REAL_t>EXP_TABLE_SIZE * 2 - 1) * MAX_EXP)\n",
    "        EXP_TABLE[i] = <REAL_t>(EXP_TABLE[i] / (EXP_TABLE[i] + 1))\n",
    "#init()\n",
    "\n",
    "\n",
    "def ctrain(A,B,C,insts,size,lr,gradient,it,Verbose=False):\n",
    "    cdef float error\n",
    "    next_random = 1\n",
    "    error = 0.\n",
    "    for i,inst in enumerate(insts):\n",
    "        err,next_random =gradient(A,B,C,inst,size,next_random,lr=lr)\n",
    "        error += err\n",
    "        if i % 1000 ==0 and Verbose:\n",
    "            sys.stdout.write(\"\\rIteration %d \" % (it)+ \"trained {0:.0f}%\".format(float(i)*100/len(insts))+\" Loss:{0:.2f}\".format(error))\n",
    "            sys.stdout.flush()\n",
    "    if Verbose:\n",
    "        sys.stdout.write(\"\\n\")\n",
    "    return error\n",
    "\n",
    "cdef void divide(REAL_t *vec, const float *alpha, const int *size):\n",
    "    cdef int i\n",
    "    for i from 0 <= i < size[0] by 1:\n",
    "        vec[i] = vec[i]/alpha[0]\n",
    "def cdivide(vec,alpha):\n",
    "    cdef int size\n",
    "    size  = len(vec)\n",
    "    cdef float r = alpha\n",
    "    divide(<REAL_t *>(np.PyArray_DATA(vec)),&r,&size)\n",
    "\n",
    "    \n",
    "cdef REAL_t matdot(vec1,mat,size):\n",
    "    cdef REAL_t product = 0.\n",
    "    for i in range(len(mat)):\n",
    "        product+= cvdot(vec1,mat[i],size)\n",
    "    return product\n",
    "\n",
    "def warp_gradient(A,B,C,inst,size,next_random,lr=0.01):\n",
    "    #print B\n",
    "    #print B[0]-B[9]\n",
    "    cdef unsigned long long  c_next_random = next_random\n",
    "    dA = np.zeros(size,dtype=REAL)\n",
    "    dB = np.zeros(B.shape,dtype=REAL)\n",
    "    x = np.sum(A[inst.features],axis=0)\n",
    "    cdef REAL_t error = 0.\n",
    "    cdef REAL_t clr = lr\n",
    "    cdef int N,n_sample \n",
    "    cdef int neg_num = len(inst.negative_labels)\n",
    "    cdef REAL_t norm\n",
    "    cdef int cSize = size\n",
    "    cdef REAL_t floats\n",
    "    M = len(inst.sparse_labels)\n",
    "    for i,l in enumerate(inst.sparse_labels):\n",
    "        y = np.dot(C[l],B)\n",
    "        s1= cvdot(x,y,size)#cvdot(x,B[l],cSize)#\n",
    "        N=1\n",
    "        n_sample  = -1\n",
    "        for k in range(neg_num):\n",
    "            c_next_random = random_int32(&c_next_random)\n",
    "            nl = inst.negative_labels[c_next_random%neg_num]#randint(0,neg_num-1)]\n",
    "            y_neg = np.dot(C[nl],B)\n",
    "            s2 = cvdot(x,y_neg,size)#cvdot(x,B[nl],size)#\n",
    "            \n",
    "            if s1 - s2<1:\n",
    "                n_sample = nl\n",
    "                N = k+1\n",
    "                break\n",
    "        if n_sample!=-1:\n",
    "\n",
    "            L = crank(len(inst.negative_labels)/N)#*(crank(M/(ranks[i]+1)))\n",
    "            negL = -L\n",
    "            error += (1+s2-s1)*L\n",
    "\n",
    "            csaxpy(y-y_neg,dA,L,size)\n",
    "            for i in range(len(dB)):\n",
    "                csaxpy(C[l][i]*x,dB[i],L,size)\n",
    "                csaxpy(C[n_sample][i]*x,dB[i],-L,size)\n",
    "            #print dB[l][0]\n",
    "    for f in inst.features:\n",
    "        csaxpy(dA,A[f],clr,size)\n",
    "        norm = cnorm(A[f])\n",
    "        if norm >1:\n",
    "            cdivide(A[f],norm)\n",
    "\n",
    "    for i in range(len(B)):\n",
    "        csaxpy(dB[i],B[i],clr,size)\n",
    "\n",
    "        #B[i] += lr*dB[i]\n",
    "        norm =  cnorm(B[i])\n",
    "        if norm >1:\n",
    "            cdivide(B[i],norm)\n",
    "            #B[i] /=norm\n",
    "    return error,c_next_random\n",
    "def save_to_text(matrix,output):\n",
    "    shape = matrix.shape\n",
    "    with open(output,'wb') as out:\n",
    "        out.write(\"%d %d\\n\" % (shape))\n",
    "        for row in matrix:\n",
    "            x = \" \".join(map(lambda x:\"{0:.5}\".format(x),row))\n",
    "            out.write(x+\"\\n\")\n",
    "\n",
    "cdef inline unsigned long long random_int32(unsigned long long *next_random) nogil:\n",
    "    next_random[0] = (next_random[0] * <unsigned long long>25214903917ULL + 11) & 281474976710655ULL\n",
    "    return next_random[0]\n",
    "def crand(sed):\n",
    "    cdef unsigned long long csed = sed\n",
    "    return random_int32(&csed)\n",
    "def save2bin(mat,dct,fn):\n",
    "    n,d  = mat.shape\n",
    "    with open(fn,'w') as out:\n",
    "        out.write(\"%d %d\\n\" % (n,d))\n",
    "        for i in range(n):\n",
    "            text = \" \".join(map(str,mat[i]))\n",
    "            out.write(\"%s %s\\n\" %(dct[i],text))\n",
    "def normalize(mat):\n",
    "    for v in mat:\n",
    "        norm = np.linalg.norm(v)\n",
    "        if norm >=1:\n",
    "            v /= norm\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set([ ln.rstrip() for ln in open('stop.list')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def total_count(d):\n",
    "    return reduce(lambda x,y:x+y,d.values(),0)\n",
    "def lambda_p(l,e,labels,entities,label_entity,t_l):\n",
    "    if \"%s_%s\" % (l,e) not in label_entity: return -1.\n",
    "    c = log(t_l)\n",
    "    return (log(labels[l]) + log(entities[e]) - 2*c)/(log(label_entity[\"%s_%s\" % (l,e)])-c) -1\n",
    "def proto(l,es,labels,entities,label_entity,t_l,topn=10):\n",
    "    scores = [lambda_p(l,e,labels,entities,label_entity,t_l) for e in es]\n",
    "    return [es[i] for i in argsort(scores,topn=topn,reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('/Volumes/My Passport/RR_backup/data/dependency_embedding/deps.words','rb') as vectors, open('/Volumes/My Passport/RR_backup/data/dependency_embedding/shortlist','wb') as out:\n",
    "    short = [ln for ln in vectors if ln.split()[0] in words.token2id]\n",
    "    out.write(\"%d %d\\n\" % (len(short),300))\n",
    "    for ln in short:\n",
    "        out.write(ln)\n",
    "words = Dictionary([e.split() for e in es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Word2Vec.load_word2vec_format('../../bow2.words',binary=True)\n",
    "t_l = total_count(labels)\n",
    "es = [e for e in entities]\n",
    "with open('labels.bin','w') as lout:\n",
    "    lout.write(\"%d %d\\n\" % (len(labels),300))\n",
    "    for l in labels:\n",
    "        protoes = proto(l,es,labels,entities,label_entity,t_l,topn=60)\n",
    "        print l,protoes\n",
    "        avg = np.zeros(300,dtype=np.float32)\n",
    "        hit = 0\n",
    "        for w in protoes:\n",
    "            if w in model.vocab:\n",
    "                hit+=1\n",
    "                avg += model[w]\n",
    "        if hit ==0:\n",
    "            print \"shit\"\n",
    "        avg /= hit\n",
    "        text =  \" \".join(map(str,avg))\n",
    "\n",
    "        lout.write(\"%s %s\\n\" % (l,text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_bin = Word2Vec.load_word2vec_format('/Users/mayk/working/figer/baseline/PLE/Model/warp/labels.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_dir= \"/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN\"\n",
    "a=MentionData('/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN/train_x_new.txt',\n",
    "              \"/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN/train_y.txt\",\n",
    "             in_dir+\"/feature.txt\",in_dir+\"/type.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 trained 100% Loss:209659.22\n",
      "Iteration 1 trained 100% Loss:138851.02\n",
      "Iteration 2 trained 100% Loss:112356.00\n",
      "Iteration 3 trained 100% Loss:96400.90\n",
      "Iteration 4 trained 100% Loss:84271.61\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "size= 50\n",
    "\n",
    "A= np.random.uniform(-6/np.sqrt(size),6/np.sqrt(size), [len(a.feature2id),size]).astype(np.float32)#np.random.rand(len(a.feature2id),size).astype(np.float32)\n",
    "C = np.asarray([label_bin[a.id2label[i]] for i in range(len(label_bin.vocab))],dtype=np.float32)\n",
    "B= np.random.uniform(-6/np.sqrt(size),6/np.sqrt(size), [C.shape[1],size]).astype(np.float32)# np.random.rand(len(a.label2id),size).astype(np.float32)\n",
    "next_random = 1\n",
    "normalize(A)\n",
    "normalize(C)\n",
    "normalize(B)\n",
    "for i in range(5): \n",
    "    reg_err =0.\n",
    "    ctrain(A,B,C,a.data,size,0.001,warp_gradient,it=i,Verbose=True)\n",
    "\n",
    "\n",
    "save2bin(A,a.id2feature,'/Users/mayk/working/figer/baseline/PLE/Results/warp_A.bin')\n",
    "\n",
    "save2bin(np.dot(C,B),a.id2label,'/Users/mayk/working/figer/baseline/PLE/Results/warp_B.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 300)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(C,B).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size =50\n",
    "C = np.asarray([label_bin[a.id2label[i]] for i in range(len(label_bin.vocab))])\n",
    "B= np.random.uniform(-6/np.sqrt(size),6/np.sqrt(size), [300,size]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location\n",
      "url\n",
      "region\n",
      "facility\n",
      "attraction\n",
      "song\n",
      "drama\n",
      "religion\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load_word2vec_format('shortlist',binary=False)\n",
    "t_l = total_count(labels)\n",
    "es = [e for e in entities]\n",
    "with open('labels.bin','w') as lout, open('/Users/mayk/working/figer/baseline/PLE/Intermediate/BBN/type_man.txt') as man:\n",
    "    lout.write(\"%d %d\\n\" % (len(labels),300))\n",
    "    for l in man:\n",
    "        l= l.rstrip().split()[3]\n",
    "        if l not in model:print l\n",
    "        #avg = model[l]\n",
    "#         hit = 0\n",
    "#         for w in protoes:\n",
    "#             if w in model.vocab:\n",
    "#                 hit+=1\n",
    "#                 avg += model[w]\n",
    "#         if hit ==0:\n",
    "#             print \"shit\"\n",
    "#         avg /= hit\n",
    "#         text =  \" \".join(map(str,avg))\n",
    "\n",
    "#         lout.write(\"%s %s\\n\" % (l,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'/ORGANIZATION/GOVERNMENT', 0.6716739535331726),\n",
       " (u'/LOCATION/LAKE_SEA_OCEAN', 0.655185878276825),\n",
       " (u'/ORGANIZATION/EDUCATIONAL', 0.6380061507225037),\n",
       " (u'/WORK_OF_ART/BOOK', 0.6343929767608643),\n",
       " (u'/ORGANIZATION/MUSEUM', 0.6125108003616333),\n",
       " (u'/FACILITY/BRIDGE', 0.6027704477310181),\n",
       " (u'/ORGANIZATION/CORPORATION', 0.5899884700775146),\n",
       " (u'/EVENT/HURRICANE', 0.5854605436325073),\n",
       " (u'/WORK_OF_ART/PLAY', 0.5838527083396912),\n",
       " (u'/LAW', 0.5786466598510742)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/WORK_OF_ART/PLAY'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word2Vec.lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
